{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries you need for your analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the previously prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining columns to work with, dropping rest basically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df.drop(['Unnamed: 0','Unnamed: 0.1','currency_symbol','disable_communication', 'friends', 'fx_rate','current_currency','usd_pledged', 'usd_type'], axis=1 , inplace=True)\n",
    "#df2 = df[['staff_pick','category_main','category_sub','duration','description_length','name_length']]\n",
    "df2 = df[['id','country','backers_count','converted_pledged_amount','staff_pick','category_main','category_sub','duration','description_length','name_length','state','goal_usd']]\n",
    "df2.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(), df.describe()\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling empty descriptions with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.description_length.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building a useless boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking various stats of our data by main categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe grouped by category with columns for failed and successful\n",
    "cat_df = pd.get_dummies(df2.set_index('category_main').state).groupby('category_main').sum()\n",
    "\n",
    "# Plotting\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(12,12))\n",
    "\n",
    "color = cm.CMRmap(np.linspace(0.1,0.6,df.category_main.nunique()))\n",
    "\n",
    "df.groupby('category_main').category_main.count().plot(kind='bar', ax=ax1, color=color)\n",
    "ax1.set_title('Amount of project by category')\n",
    "ax1.set_xlabel('')\n",
    "\n",
    "df.groupby('category_main').goal_usd.median().plot(kind='bar', ax=ax2, color=color)\n",
    "ax2.set_title('Median project goal ($)')\n",
    "ax2.set_xlabel('')\n",
    "\n",
    "df.groupby('category_main').converted_pledged_amount.median().plot(kind='bar', ax=ax3, color=color)\n",
    "ax3.set_title('Median pledged per project ($)')\n",
    "ax3.set_xlabel('')\n",
    "\n",
    "cat_df.div(cat_df.sum(axis=1), axis=0).successful.plot(kind='bar', ax=ax4, color=color) # Normalizes counts across rows\n",
    "ax4.set_title('Proportion of successful projects')\n",
    "ax4.set_xlabel('')\n",
    "\n",
    "df.groupby('category_main').backers_count.median().plot(kind='bar', ax=ax5, color=color)\n",
    "ax5.set_title('Median backers per project')\n",
    "ax5.set_xlabel('')\n",
    "\n",
    "df.groupby('category_main').backers_count.mean().plot(kind='bar', ax=ax6, color=color)\n",
    "ax6.set_title('Mean backers per project')\n",
    "ax6.set_xlabel('')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping potential data leakage from the data and not used data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.columns\n",
    "df_clean = df2.drop(['backers_count','converted_pledged_amount','duration',],axis=1)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building a simple log reg model only with main categories and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a simple model before applying all data above\n",
    "\n",
    "df_cm = df2[['state','category_main']]\n",
    "df_cm['state'] = df_cm['state'].replace({'failed': 0, 'successful': 1})\n",
    "df_cm = pd.get_dummies(df_cm)\n",
    "y_simple = df_cm['state']\n",
    "X_simple = df_cm.drop('state',axis=1)\n",
    "#no need to scale data, only 0 and 1\n",
    "X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(X_simple, y_simple, stratify = y_simple, random_state=RSEED)\n",
    "\n",
    "Lgsimple = LogisticRegression()\n",
    "Lgsimple.fit(X_train_simple,y_train_simple)\n",
    "y_p_simple = Lgsimple.predict(X_test_simple)\n",
    "\n",
    "print(\"Performance on test set: \",Lgsimple.score(X_test_simple, y_test_simple))\n",
    "print(classification_report(y_test_simple,y_p_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking subcategories' value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.category_sub.value_counts()\n",
    "#dropping subcategory > too many dummy columns\n",
    "df_clean = df_clean.drop('category_sub',axis=1)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforming state to 0 & 1 and getting dummy variables for other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['state'] = df_clean['state'].replace({'failed': 0, 'successful': 1})\n",
    "df_clean = pd.get_dummies(df_clean)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our target dataframe and features dataframe, performing a train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = df_clean[\"state\"]\n",
    "X = df_clean.drop(\"state\", axis=1)\n",
    "\n",
    "scaling = StandardScaler()\n",
    "X_scaled = scaling.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = list(X.columns))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and train data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify = y, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple logistic regression model\n",
    "\n",
    "\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting and printing classification report\n",
    "\n",
    "\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "print(\"Performance on test set: \",LogReg.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying more complex model with Decision tree\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on test set: \",tree.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_test,y_pred_tree))\n",
    "print(confusion_matrix(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without optimization Logistic Regression performs better overall. Recall is worse for DCT than for LG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc42540fe103dd469b6725b57967c12f40a7d17b537c2890cc57fdaceb51611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
